# Data Model: GitOps Workflow Lab for Azure ML

**Feature**: 001-gitops-lab-workflow
**Date**: 2026-01-27

## Entities

### E1: Training Dataset

Generated by `train_model.py`. 10,000 records with fixed seed (42).

| Field | Type | Range/Values | Description |
|-------|------|-------------|-------------|
| customer_id | string | "CUST-00001" to "CUST-10000" | Unique customer identifier |
| tenure_months | int | 1-72 | Months as customer |
| monthly_charges | float | 20.0-120.0 | Monthly bill in USD |
| total_charges | float | computed | tenure_months * monthly_charges (with noise) |
| contract_type | categorical | "month-to-month", "one-year", "two-year" | Contract duration |
| internet_service | categorical | "dsl", "fiber_optic", "no" | Internet service type |
| payment_method | categorical | "electronic_check", "mailed_check", "bank_transfer", "credit_card" | Payment method |
| num_support_tickets | int | 0-10 | Support tickets in last year |
| churned | binary (0/1) | 0 or 1 | Target: did customer churn? |

**Churn probability logic** (for synthetic generation):
- Higher churn for month-to-month contracts (~40%)
- Higher churn for electronic_check payment (~35%)
- Higher churn for fiber_optic with high support tickets
- Lower churn for long tenure (>24 months)

### E2: Inference Dataset

Generated by `create_inference_data.py`. 500 records, same schema as E1 except **no `churned` column**.

| Field | Type | Same as E1 |
|-------|------|-----------|
| customer_id | string | Yes (different IDs: "CUST-10001" to "CUST-10500") |
| tenure_months | int | Yes |
| monthly_charges | float | Yes |
| total_charges | float | Yes |
| contract_type | categorical | Yes |
| internet_service | categorical | Yes |
| payment_method | categorical | Yes |
| num_support_tickets | int | Yes |

**File**: `data/inference_input.csv`

### E3: Predictions Dataset

Output of the Azure ML inference pipeline. Same as E2 plus prediction column.

| Field | Type | Description |
|-------|------|-------------|
| *(all E2 fields)* | *(same)* | Original input features |
| churn_probability | float (0.0-1.0) | Predicted probability of churn |

**File**: Downloaded from Azure ML pipeline output as `data/inference_output.csv`

### E4: Model Artifact

Generated by `train_model.py`, registered by `register_model.py`.

| Artifact | Format | Location |
|----------|--------|----------|
| model.pkl | Python pickle (scikit-learn RandomForestClassifier) | Local: `artifacts/model.pkl` |
| model_metadata.json | JSON | Local: `artifacts/model_metadata.json` |
| Registered model | MLflow model | Azure ML: Model Registry |

**model_metadata.json schema**:
```json
{
  "model_name": "churn-prediction-model",
  "model_type": "RandomForestClassifier",
  "training_date": "2026-01-27T10:30:00",
  "num_samples": 10000,
  "features": ["tenure_months", "monthly_charges", ...],
  "metrics": {
    "accuracy": 0.85,
    "precision": 0.82,
    "recall": 0.78,
    "f1_score": 0.80
  },
  "random_seed": 42
}
```

### E5: Azure ML Workspace Configuration

Stored in `config.json` (gitignored, created by student).

| Field | Type | Description |
|-------|------|-------------|
| subscription_id | string (UUID) | Azure subscription ID |
| resource_group | string | Azure resource group name |
| workspace_name | string | Azure ML workspace name |

### E6: GitHub Secrets (Bonus Section)

Configured in GitHub Settings > Secrets for automated workflows.

| Secret Name | Description | Used By |
|-------------|-------------|---------|
| AZURE_TENANT_ID | Azure AD tenant ID | deploy_model.yml |
| AZURE_CLIENT_ID | Service Principal app ID | deploy_model.yml |
| AZURE_CLIENT_SECRET | Service Principal password | deploy_model.yml |
| AZURE_SUBSCRIPTION_ID | Azure subscription ID | deploy_model.yml |
| AZURE_RESOURCE_GROUP | Resource group name | deploy_model.yml |
| AZURE_ML_WORKSPACE_NAME | Workspace name | deploy_model.yml |

## Relationships

```
Training Dataset --[trains]--> Model Artifact
Model Artifact --[registered in]--> Azure ML Model Registry (MLflow)
Inference Dataset --[uploaded to]--> Azure ML Data Asset
Azure ML Pipeline --[reads]--> Azure ML Data Asset + Registered Model
Azure ML Pipeline --[produces]--> Predictions Dataset
config.json --[connects]--> Azure ML Workspace
GitHub Secrets --[authenticates]--> deploy_model.yml --> Azure ML Workspace
```

## State Transitions

### Model Lifecycle
1. **Local** (artifacts/model.pkl) - Created by train_model.py
2. **Verified** - Tested by test_model.py
3. **Registered** - Uploaded to Azure ML via register_model.py
4. **Deployed** (optional) - Used in inference pipeline

### Pipeline Data Flow
1. **Generated** (data/inference_input.csv) - Created by create_inference_data.py
2. **Uploaded** (Azure ML Data Asset) - Uploaded by upload_data.py
3. **Processed** (Azure ML Pipeline) - Consumed by run_inference_pipeline.py / score.py
4. **Output** (Azure ML Datastore) - Predictions CSV saved
5. **Downloaded** (data/inference_output.csv) - Student downloads results
